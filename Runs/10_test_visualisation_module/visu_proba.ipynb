{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from soma import aims\n",
    "# import anatomist.api as ana\n",
    "from betaVAE.beta_vae import VAE\n",
    "from betaVAE.visualisation_anatomist import adjust_in_shape\n",
    "from pathlib import Path\n",
    "from betaVAE.preprocess import UkbDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ROOT_SAVE = Path(\"/neurospin/dico/tsanchez/tmp\")\n",
    "\n",
    "PATH_EXP = Path(\"/neurospin/dico/tsanchez/Test_BetaVAE/2025-05-27/16-52-59_\")\n",
    "PATH_MODEL = PATH_EXP / \"checkpoint.pt\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "N_LATENT = 1024\n",
    "DEPTH = 3\n",
    "\n",
    "IN_SHAPE_WOUT_ADJUST = [1, 54, 120, 139] #One from the config.yaml file\n",
    "IN_SHAPE = adjust_in_shape(IN_SHAPE_WOUT_ADJUST, depth=DEPTH)\n",
    "\n",
    "CONFIG = {\n",
    "    \"in_shape\" : IN_SHAPE,\n",
    "    \"root\" : \"/neurospin/dico/tsanchez/preprocessed/UKBio1000\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1     [-1, 16, 60, 120, 144]             448\n",
      "       BatchNorm3d-2     [-1, 16, 60, 120, 144]              32\n",
      "         LeakyReLU-3     [-1, 16, 60, 120, 144]               0\n",
      "            Conv3d-4       [-1, 16, 30, 60, 72]          16,400\n",
      "       BatchNorm3d-5       [-1, 16, 30, 60, 72]              32\n",
      "         LeakyReLU-6       [-1, 16, 30, 60, 72]               0\n",
      "            Conv3d-7       [-1, 32, 30, 60, 72]          13,856\n",
      "       BatchNorm3d-8       [-1, 32, 30, 60, 72]              64\n",
      "         LeakyReLU-9       [-1, 32, 30, 60, 72]               0\n",
      "           Conv3d-10       [-1, 32, 15, 30, 36]          65,568\n",
      "      BatchNorm3d-11       [-1, 32, 15, 30, 36]              64\n",
      "        LeakyReLU-12       [-1, 32, 15, 30, 36]               0\n",
      "           Conv3d-13       [-1, 64, 15, 30, 36]          55,360\n",
      "      BatchNorm3d-14       [-1, 64, 15, 30, 36]             128\n",
      "        LeakyReLU-15       [-1, 64, 15, 30, 36]               0\n",
      "           Conv3d-16        [-1, 64, 7, 15, 18]         262,208\n",
      "      BatchNorm3d-17        [-1, 64, 7, 15, 18]             128\n",
      "        LeakyReLU-18        [-1, 64, 7, 15, 18]               0\n",
      "           Linear-19                 [-1, 1024]     123,864,064\n",
      "           Linear-20                 [-1, 1024]     123,864,064\n",
      "           Linear-21               [-1, 120960]     123,984,000\n",
      "  ConvTranspose3d-22       [-1, 32, 15, 30, 36]          16,416\n",
      "      BatchNorm3d-23       [-1, 32, 15, 30, 36]              64\n",
      "             ReLU-24       [-1, 32, 15, 30, 36]               0\n",
      "  ConvTranspose3d-25       [-1, 32, 15, 30, 36]          27,680\n",
      "      BatchNorm3d-26       [-1, 32, 15, 30, 36]              64\n",
      "             ReLU-27       [-1, 32, 15, 30, 36]               0\n",
      "  ConvTranspose3d-28       [-1, 16, 30, 60, 72]           4,112\n",
      "      BatchNorm3d-29       [-1, 16, 30, 60, 72]              32\n",
      "             ReLU-30       [-1, 16, 30, 60, 72]               0\n",
      "  ConvTranspose3d-31       [-1, 16, 30, 60, 72]           6,928\n",
      "      BatchNorm3d-32       [-1, 16, 30, 60, 72]              32\n",
      "             ReLU-33       [-1, 16, 30, 60, 72]               0\n",
      "  ConvTranspose3d-34      [-1, 1, 60, 120, 144]             129\n",
      "           Conv3d-35      [-1, 1, 60, 120, 144]               2\n",
      "================================================================\n",
      "Total params: 372,181,875\n",
      "Trainable params: 372,181,875\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.96\n",
      "Forward/backward pass size (MB): 695.85\n",
      "Params size (MB): 1419.76\n",
      "Estimated Total Size (MB): 2119.56\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104528/151149905.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(PATH_MODEL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['encoder.conv0.weight', 'encoder.conv0.bias', 'encoder.norm0.weight', 'encoder.norm0.bias', 'encoder.norm0.running_mean', 'encoder.norm0.running_var', 'encoder.norm0.num_batches_tracked', 'encoder.conv0a.weight', 'encoder.conv0a.bias', 'encoder.norm0a.weight', 'encoder.norm0a.bias', 'encoder.norm0a.running_mean', 'encoder.norm0a.running_var', 'encoder.norm0a.num_batches_tracked', 'encoder.conv1.weight', 'encoder.conv1.bias', 'encoder.norm1.weight', 'encoder.norm1.bias', 'encoder.norm1.running_mean', 'encoder.norm1.running_var', 'encoder.norm1.num_batches_tracked', 'encoder.conv1a.weight', 'encoder.conv1a.bias', 'encoder.norm1a.weight', 'encoder.norm1a.bias', 'encoder.norm1a.running_mean', 'encoder.norm1a.running_var', 'encoder.norm1a.num_batches_tracked', 'encoder.conv2.weight', 'encoder.conv2.bias', 'encoder.norm2.weight', 'encoder.norm2.bias', 'encoder.norm2.running_mean', 'encoder.norm2.running_var', 'encoder.norm2.num_batches_tracked', 'encoder.conv2a.weight', 'encoder.conv2a.bias', 'encoder.norm2a.weight', 'encoder.norm2a.bias', 'encoder.norm2a.running_mean', 'encoder.norm2a.running_var', 'encoder.norm2a.num_batches_tracked', 'z_mean.weight', 'z_mean.bias', 'z_var.weight', 'z_var.bias', 'z_develop.weight', 'z_develop.bias', 'decoder.convTrans3d0.weight', 'decoder.convTrans3d0.bias', 'decoder.normup0.weight', 'decoder.normup0.bias', 'decoder.normup0.running_mean', 'decoder.normup0.running_var', 'decoder.normup0.num_batches_tracked', 'decoder.convTrans3d0a.weight', 'decoder.convTrans3d0a.bias', 'decoder.normup0a.weight', 'decoder.normup0a.bias', 'decoder.normup0a.running_mean', 'decoder.normup0a.running_var', 'decoder.normup0a.num_batches_tracked', 'decoder.convTrans3d1.weight', 'decoder.convTrans3d1.bias', 'decoder.normup1.weight', 'decoder.normup1.bias', 'decoder.normup1.running_mean', 'decoder.normup1.running_var', 'decoder.normup1.num_batches_tracked', 'decoder.convTrans3d1a.weight', 'decoder.convTrans3d1a.bias', 'decoder.normup1a.weight', 'decoder.normup1a.bias', 'decoder.normup1a.running_mean', 'decoder.normup1a.running_var', 'decoder.normup1a.num_batches_tracked', 'decoder.convtrans3dn.weight', 'decoder.convtrans3dn.bias', 'decoder.conv_final.weight', 'decoder.conv_final.bias'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (conv0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (norm0): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU0): LeakyReLU(negative_slope=0.01)\n",
       "    (conv0a): Conv3d(16, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (norm0a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU0a): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU1): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1a): Conv3d(32, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (norm1a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU1a): LeakyReLU(negative_slope=0.01)\n",
       "    (conv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU2): LeakyReLU(negative_slope=0.01)\n",
       "    (conv2a): Conv3d(64, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (norm2a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU2a): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (z_mean): Linear(in_features=120960, out_features=1024, bias=True)\n",
       "  (z_var): Linear(in_features=120960, out_features=1024, bias=True)\n",
       "  (z_develop): Linear(in_features=1024, out_features=120960, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (convTrans3d0): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), output_padding=(1, 0, 0))\n",
       "    (normup0): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU0): ReLU()\n",
       "    (convTrans3d0a): ConvTranspose3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (normup0a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU0a): ReLU()\n",
       "    (convTrans3d1): ConvTranspose3d(32, 16, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (normup1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU1): ReLU()\n",
       "    (convTrans3d1a): ConvTranspose3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (normup1a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU1a): ReLU()\n",
       "    (convtrans3dn): ConvTranspose3d(16, 1, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (conv_final): Conv3d(1, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = VAE(\n",
    "    in_shape=IN_SHAPE, \n",
    "    n_latent=N_LATENT,\n",
    "    depth=DEPTH\n",
    ")\n",
    "summary(model.cuda(), tuple(IN_SHAPE))\n",
    "\n",
    "state_dict = torch.load(PATH_MODEL)\n",
    "print(state_dict.keys())\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UkbDataset(CONFIG)\n",
    "loader = DataLoader(dataset=dataset, shuffle=True, batch_size=5)\n",
    "split_batch, full_batch ,list_sub = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2, 60, 120, 144]), torch.Size([5, 1, 60, 120, 144]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = split_batch[:,0,:,:,:].unsqueeze(1)\n",
    "split_batch.shape, batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 60, 120, 144])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batch.to(device, dtype = torch.float32)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((batch, list_sub, output_batch), ROOT_SAVE / \"proba_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104528/3503111725.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  batch, list_sub, output_batch = torch.load(ROOT_SAVE / \"proba_test.pt\")\n"
     ]
    }
   ],
   "source": [
    "batch, list_sub, output_batch = torch.load(ROOT_SAVE / \"proba_test.pt\")\n",
    "batch = batch.to(device = \"cpu\")\n",
    "out_proba = output_batch[0].to(device = \"cpu\")\n",
    "z = output_batch[1].to(device = \"cpu\")\n",
    "logvar = output_batch[2].to(device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3260, grad_fn=<MaxBackward1>),\n",
       " tensor(-0.5988, grad_fn=<MinBackward1>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(out_proba[0]), torch.min(out_proba[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create qapp\n",
      "done\n",
      "Starting Anatomist.....\n",
      "config file : /home/ts283124/.anatomist/config/settings.cfg\n",
      "PyAnatomist Module present\n",
      "PythonLauncher::runModules()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "existing QApplication: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global modules: /neurospin/dico/tsanchez/2025_tsanchez_cerrebellum/soma-env/build/share/anatomist-5.2/python_plugins\n",
      "home   modules: /home/ts283124/.anatomist/python_plugins\n",
      "loading module gltf_io\n",
      "loading module palettecontrols\n",
      "loading module paletteViewer\n",
      "loading module meshsplit\n",
      "loading module profilewindow\n",
      "loading module ana_image_math\n",
      "loading module anacontrolmenu\n",
      "loading module foldsplit\n",
      "loading module modelGraphs\n",
      "loading module bsa_proba\n",
      "loading module histogram\n",
      "loading module gradientpalette\n",
      "loading module infowindow\n",
      "loading module simple_controls\n",
      "loading module volumepalettes\n",
      "loading module statsplotwindow\n",
      "loading module save_resampled\n",
      "loading module valuesplotwindow\n",
      "loading module selection\n",
      "all python modules loaded\n",
      "Anatomist started.\n",
      "Multitexturing present\n",
      "function glActiveTexture found.\n",
      "function glClientActiveTexture found.\n",
      "function glBlendEquation found.\n",
      "function glTexImage3D found.\n",
      "function glMultiTexCoord3f found.\n",
      "function glBindFramebuffer found.\n",
      "function glBindRenderbuffer found.\n",
      "function glFramebufferTexture2D found.\n",
      "function glGenFramebuffers found.\n",
      "function glGenRenderbuffers found.\n",
      "function glFramebufferRenderbuffer found.\n",
      "function glRenderbufferStorage found.\n",
      "function glCheckFramebufferStatus found.\n",
      "function glDeleteRenderbuffers found.\n",
      "function glDeleteFramebuffers found.\n",
      "Number of texture units: 8\n",
      "function glUniform1f found.\n",
      "function glUniform1i found.\n",
      "function glUniform4fv found.\n",
      "function glGetUniformLocation found.\n",
      "function glMultTransposeMatrixf found.\n",
      "function glAttachShader found.\n",
      "function glDetachShader found.\n",
      "function glCompileShader found.\n",
      "function glCreateProgram found.\n",
      "function glCreateShader found.\n",
      "function glDeleteProgram found.\n",
      "function glDeleteShader found.\n",
      "function glGetProgramiv found.\n",
      "function glGetShaderiv found.\n",
      "function glLinkProgram found.\n",
      "function glShaderSource found.\n",
      "function glUseProgram found.\n",
      "GL_ARB_shadow present\n",
      "GL_SGIX_shadow extension not available\n",
      "GL_SGIX_depth_texture extension not available\n",
      "GL_ARB_depth_texture extension present\n",
      "GL_ARB_texture_cube_map extension present\n",
      "GL_EXT_texture_cube_map extension present\n",
      "Number of texture units: 8\n"
     ]
    }
   ],
   "source": [
    "import anatomist.api as ana\n",
    "from soma import aims\n",
    "anatomist = ana.Anatomist()\n",
    "win = anatomist.createWindow(\"3D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input volume\n",
    "input_vol = aims.Volume(batch[0].squeeze(0).numpy())\n",
    "ana_input = anatomist.toAObject(input_vol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 60, 120, 144])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import sigmoid\n",
    "sample = out_proba[0]\n",
    "print(sample.shape)\n",
    "proba = sigmoid(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 120, 144])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no position could be read at 213, 32\n",
      "Exiting QApplication\n"
     ]
    }
   ],
   "source": [
    "to_plot = proba[0]\n",
    "print(to_plot.shape)\n",
    "proba_vol = aims.Volume(to_plot.detach().numpy())\n",
    "proba_ana = anatomist.toAObject(proba_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
