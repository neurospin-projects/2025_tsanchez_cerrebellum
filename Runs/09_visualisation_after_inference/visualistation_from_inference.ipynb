{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_saving_folder = Path(\"/neurospin/dico/tsanchez/Test_BetaVAE/2025-04-22\")\n",
    "timestamp = \"13-45-45\"\n",
    "name_checkpoint = \"checkpoint.pt\"\n",
    "\n",
    "path_model = root_saving_folder / timestamp / name_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_in_shape(in_shape, depth):\n",
    "    \"\"\"\n",
    "    Function to make sure that the output of the encoder is composed of integers \n",
    "    In this case : Each block (conv_x + conv_x_a) reduce by 2 the dimension of the volume.\n",
    "    \"\"\"\n",
    "\n",
    "    dims=[]\n",
    "    for idx in range(1, 4):\n",
    "        dim = in_shape[idx]\n",
    "        r = dim%(2**depth)\n",
    "        if r!=0:\n",
    "            dim+=(2**depth-r)\n",
    "        dims.append(dim)\n",
    "    return((1, dims[0]+4, dims[1], dims[2])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2779551/3755725018.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path_model))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (conv0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (norm0): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU0): LeakyReLU(negative_slope=0.01)\n",
       "    (conv0a): Conv3d(16, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (norm0a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU0a): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU1): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1a): Conv3d(32, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (norm1a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU1a): LeakyReLU(negative_slope=0.01)\n",
       "    (conv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU2): LeakyReLU(negative_slope=0.01)\n",
       "    (conv2a): Conv3d(64, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (norm2a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyReLU2a): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (z_mean): Linear(in_features=120960, out_features=64, bias=True)\n",
       "  (z_var): Linear(in_features=120960, out_features=64, bias=True)\n",
       "  (z_develop): Linear(in_features=64, out_features=120960, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (convTrans3d0): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), output_padding=(1, 0, 0))\n",
       "    (normup0): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU0): ReLU()\n",
       "    (convTrans3d0a): ConvTranspose3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (normup0a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU0a): ReLU()\n",
       "    (convTrans3d1): ConvTranspose3d(32, 16, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (normup1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU1): ReLU()\n",
       "    (convTrans3d1a): ConvTranspose3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (normup1a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU1a): ReLU()\n",
       "    (convtrans3dn): ConvTranspose3d(16, 1, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (conv_final): Conv3d(1, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from betaVAE.beta_vae import VAE\n",
    "\n",
    "device = \"cuda:0\"\n",
    "DEPTH = 3\n",
    "\n",
    "IN_SHAPE_WOUT_ADJUST = [1, 54, 120, 139] #One from the config.yaml file\n",
    "IN_SHAPE = adjust_in_shape(IN_SHAPE_WOUT_ADJUST, depth=DEPTH)\n",
    "\n",
    "# ! Specific to the different models\n",
    "N_LATENT = 64 \n",
    "model = VAE(\n",
    "    in_shape=IN_SHAPE, \n",
    "    n_latent=N_LATENT,\n",
    "    depth=DEPTH\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(path_model))\n",
    "model.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'omegaconf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbetaVAE\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocess\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UkbDataset\n\u001b[32m      2\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33min_shape\u001b[39m\u001b[33m\"\u001b[39m : IN_SHAPE,\n\u001b[32m      3\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mroot\u001b[39m\u001b[33m\"\u001b[39m : \u001b[33m\"\u001b[39m\u001b[33m/neurospin/dico/tsanchez/preprocessed/UKBio1000\u001b[39m\u001b[33m\"\u001b[39m }\n\u001b[32m      4\u001b[39m dataset = UkbDataset(config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/neurospin/dico/tsanchez/2025_tsanchez_cerrebellum/Runs/09_visualisation_after_inference/betaVAE/preprocess.py:46\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01momegaconf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DictConfig\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransforms\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'omegaconf'"
     ]
    }
   ],
   "source": [
    "from betaVAE.preprocess import UkbDataset\n",
    "config = {\"in_shape\" : IN_SHAPE,\n",
    "          \"root\" : \"/neurospin/dico/tsanchez/preprocessed/UKBio1000\" }\n",
    "dataset = UkbDataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sub-2614736',\n",
       " torch.Size([1, 1, 60, 120, 144]),\n",
       " tensor([-1.,  0.,  1.], device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBJECT_IND = 42\n",
    "tensor, sub_id = dataset[SUBJECT_IND]\n",
    "tensor = tensor.to(device= device, dtype = torch.float32).unsqueeze(0)\n",
    "sub_id, tensor.shape, torch.unique(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[[ 1.3208e-01,  1.3483e-01,  1.4111e-01,  ...,  1.4068e-01,\n",
       "              1.3751e-01,  1.2757e-01],\n",
       "            [ 1.4849e-01,  1.6506e-01,  1.5217e-01,  ...,  2.0958e-01,\n",
       "              1.5025e-01,  2.0253e-01],\n",
       "            [ 1.3577e-01,  1.3803e-01,  1.3631e-01,  ...,  1.5008e-01,\n",
       "              1.3382e-01,  1.3652e-01],\n",
       "            ...,\n",
       "            [ 1.4228e-01,  1.6233e-01,  1.5810e-01,  ...,  1.9755e-01,\n",
       "              1.4937e-01,  2.1839e-01],\n",
       "            [ 1.2697e-01,  1.3289e-01,  1.2972e-01,  ...,  1.4054e-01,\n",
       "              1.3040e-01,  1.3113e-01],\n",
       "            [ 1.3699e-01,  1.2945e-01,  1.4149e-01,  ...,  1.5074e-01,\n",
       "              1.3854e-01,  1.3471e-01]],\n",
       " \n",
       "           [[ 1.7632e-01,  1.4671e-01,  2.1302e-01,  ...,  1.6143e-01,\n",
       "              2.1969e-01,  1.3753e-01],\n",
       "            [ 1.3194e-01,  1.6447e-01,  1.5202e-01,  ...,  1.9515e-01,\n",
       "              1.4515e-01,  1.8225e-01],\n",
       "            [ 2.3020e-01,  1.6599e-01,  2.5777e-01,  ...,  1.9003e-01,\n",
       "              2.3867e-01,  1.5434e-01],\n",
       "            ...,\n",
       "            [ 1.2996e-01,  1.6799e-01,  1.6140e-01,  ...,  2.0005e-01,\n",
       "              1.4820e-01,  1.8542e-01],\n",
       "            [ 1.9232e-01,  1.5325e-01,  2.0992e-01,  ...,  1.7251e-01,\n",
       "              1.9180e-01,  1.4240e-01],\n",
       "            [ 1.3269e-01,  1.6234e-01,  1.4161e-01,  ...,  1.8678e-01,\n",
       "              1.3320e-01,  1.5261e-01]],\n",
       " \n",
       "           [[ 1.4092e-01,  1.6339e-01,  1.7569e-01,  ...,  1.6734e-01,\n",
       "              1.7012e-01,  1.4283e-01],\n",
       "            [ 1.6322e-01,  2.9248e-01,  1.9872e-01,  ...,  3.5496e-01,\n",
       "              2.0026e-01,  3.3612e-01],\n",
       "            [ 1.5329e-01,  1.6731e-01,  1.9313e-01,  ...,  1.7759e-01,\n",
       "              1.8660e-01,  1.6009e-01],\n",
       "            ...,\n",
       "            [ 1.6228e-01,  3.2689e-01,  2.1148e-01,  ...,  3.7856e-01,\n",
       "              2.0971e-01,  3.3880e-01],\n",
       "            [ 1.5187e-01,  1.5805e-01,  1.6772e-01,  ...,  1.6866e-01,\n",
       "              1.5267e-01,  1.5947e-01],\n",
       "            [ 1.5126e-01,  2.0837e-01,  1.8109e-01,  ...,  2.1769e-01,\n",
       "              1.7509e-01,  2.0120e-01]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[ 1.4063e-01,  1.3317e-01,  1.7109e-01,  ...,  1.5341e-01,\n",
       "              1.8525e-01,  1.3689e-01],\n",
       "            [ 1.2130e-01,  1.3819e-01,  1.3718e-01,  ...,  1.7227e-01,\n",
       "              1.3336e-01,  1.7005e-01],\n",
       "            [ 1.6097e-01,  1.4109e-01,  2.0055e-01,  ...,  1.7397e-01,\n",
       "              2.0598e-01,  1.4076e-01],\n",
       "            ...,\n",
       "            [ 1.2334e-01,  1.5375e-01,  1.4140e-01,  ...,  1.6328e-01,\n",
       "              1.3266e-01,  1.6394e-01],\n",
       "            [ 1.3546e-01,  1.2580e-01,  1.6747e-01,  ...,  1.4602e-01,\n",
       "              1.6357e-01,  1.3271e-01],\n",
       "            [ 1.2075e-01,  1.3305e-01,  1.3175e-01,  ...,  1.5086e-01,\n",
       "              1.2904e-01,  1.4666e-01]],\n",
       " \n",
       "           [[ 1.2344e-01,  1.3568e-01,  1.3643e-01,  ...,  1.4251e-01,\n",
       "              1.3780e-01,  1.3504e-01],\n",
       "            [ 1.3885e-01,  1.8965e-01,  1.4729e-01,  ...,  2.1614e-01,\n",
       "              1.5474e-01,  1.9031e-01],\n",
       "            [ 1.3006e-01,  1.3671e-01,  1.4678e-01,  ...,  1.4665e-01,\n",
       "              1.4035e-01,  1.3535e-01],\n",
       "            ...,\n",
       "            [ 1.4570e-01,  2.2512e-01,  1.5094e-01,  ...,  2.1926e-01,\n",
       "              1.4826e-01,  1.7878e-01],\n",
       "            [ 1.2533e-01,  1.2924e-01,  1.2612e-01,  ...,  1.3121e-01,\n",
       "              1.2499e-01,  1.2892e-01],\n",
       "            [ 1.3607e-01,  1.3376e-01,  1.3604e-01,  ...,  1.4457e-01,\n",
       "              1.3810e-01,  1.4688e-01]],\n",
       " \n",
       "           [[ 1.4356e-01,  1.2467e-01,  1.9470e-01,  ...,  1.2675e-01,\n",
       "              1.9454e-01,  1.4115e-01],\n",
       "            [ 1.2749e-01,  1.5671e-01,  1.3699e-01,  ...,  1.6546e-01,\n",
       "              1.3205e-01,  1.6648e-01],\n",
       "            [ 1.6624e-01,  1.3603e-01,  1.9448e-01,  ...,  1.4815e-01,\n",
       "              2.0070e-01,  1.3608e-01],\n",
       "            ...,\n",
       "            [ 1.2523e-01,  1.6635e-01,  1.3838e-01,  ...,  1.6420e-01,\n",
       "              1.3233e-01,  1.5784e-01],\n",
       "            [ 1.4099e-01,  1.2855e-01,  1.2933e-01,  ...,  1.2997e-01,\n",
       "              1.3702e-01,  1.2694e-01],\n",
       "            [ 1.2576e-01,  1.4007e-01,  1.2088e-01,  ...,  1.3790e-01,\n",
       "              1.2174e-01,  1.4253e-01]]],\n",
       " \n",
       " \n",
       "          [[[ 3.4506e-01,  4.6145e-01,  7.2785e-01,  ...,  7.0975e-01,\n",
       "              5.7508e-01,  1.5335e-01],\n",
       "            [ 1.0411e+00,  1.7443e+00,  1.1974e+00,  ...,  3.6330e+00,\n",
       "              1.1158e+00,  3.3341e+00],\n",
       "            [ 5.0164e-01,  5.9718e-01,  5.2434e-01,  ...,  1.1086e+00,\n",
       "              4.1867e-01,  5.3332e-01],\n",
       "            ...,\n",
       "            [ 7.7754e-01,  1.6284e+00,  1.4490e+00,  ...,  3.1227e+00,\n",
       "              1.0783e+00,  4.0072e+00],\n",
       "            [ 1.2825e-01,  3.7941e-01,  2.4466e-01,  ...,  7.0378e-01,\n",
       "              2.7377e-01,  3.0463e-01],\n",
       "            [ 5.5326e-01,  2.3336e-01,  7.4412e-01,  ...,  1.1364e+00,\n",
       "              6.1891e-01,  4.5662e-01]],\n",
       " \n",
       "           [[ 2.2221e+00,  9.6579e-01,  3.7791e+00,  ...,  1.5901e+00,\n",
       "              4.0620e+00,  5.7617e-01],\n",
       "            [ 3.3889e-01,  1.7190e+00,  1.1907e+00,  ...,  3.0207e+00,\n",
       "              8.9940e-01,  2.4736e+00],\n",
       "            [ 4.5080e+00,  1.7838e+00,  5.6778e+00,  ...,  2.8038e+00,\n",
       "              4.8676e+00,  1.2893e+00],\n",
       "            ...,\n",
       "            [ 2.5481e-01,  1.8686e+00,  1.5890e+00,  ...,  3.2289e+00,\n",
       "              1.0288e+00,  2.6080e+00],\n",
       "            [ 2.9010e+00,  1.2432e+00,  3.6477e+00,  ...,  2.0602e+00,\n",
       "              2.8787e+00,  7.8289e-01],\n",
       "            [ 3.7079e-01,  1.6287e+00,  7.4912e-01,  ...,  2.6659e+00,\n",
       "              3.9239e-01,  1.2158e+00]],\n",
       " \n",
       "           [[ 7.1980e-01,  1.6732e+00,  2.1953e+00,  ...,  1.8409e+00,\n",
       "              1.9588e+00,  8.0115e-01],\n",
       "            [ 1.6662e+00,  7.1507e+00,  3.1723e+00,  ...,  9.8017e+00,\n",
       "              3.2376e+00,  9.0021e+00],\n",
       "            [ 1.2446e+00,  1.8397e+00,  2.9353e+00,  ...,  2.2758e+00,\n",
       "              2.6580e+00,  1.5335e+00],\n",
       "            ...,\n",
       "            [ 1.6261e+00,  8.6105e+00,  3.7140e+00,  ...,  1.0803e+01,\n",
       "              3.6389e+00,  9.1160e+00],\n",
       "            [ 1.1848e+00,  1.4469e+00,  1.8569e+00,  ...,  1.8968e+00,\n",
       "              1.2186e+00,  1.5070e+00],\n",
       "            [ 1.1586e+00,  3.5818e+00,  2.4244e+00,  ...,  3.9774e+00,\n",
       "              2.1697e+00,  3.2775e+00]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[ 7.0774e-01,  3.9098e-01,  2.0000e+00,  ...,  1.2499e+00,\n",
       "              2.6010e+00,  5.4889e-01],\n",
       "            [-1.1273e-01,  6.0403e-01,  5.6146e-01,  ...,  2.0501e+00,\n",
       "              3.9908e-01,  1.9562e+00],\n",
       "            [ 1.5706e+00,  7.2728e-01,  3.2499e+00,  ...,  2.1221e+00,\n",
       "              3.4804e+00,  7.1303e-01],\n",
       "            ...,\n",
       "            [-2.6039e-02,  1.2642e+00,  7.4018e-01,  ...,  1.6689e+00,\n",
       "              3.6939e-01,  1.6967e+00],\n",
       "            [ 4.8834e-01,  7.8372e-02,  1.8463e+00,  ...,  9.3628e-01,\n",
       "              1.6811e+00,  3.7156e-01],\n",
       "            [-1.3606e-01,  3.8606e-01,  3.3073e-01,  ...,  1.1418e+00,\n",
       "              2.1603e-01,  9.6337e-01]],\n",
       " \n",
       "           [[-2.1554e-02,  4.9742e-01,  5.2962e-01,  ...,  7.8754e-01,\n",
       "              5.8755e-01,  4.7029e-01],\n",
       "            [ 6.3201e-01,  2.7874e+00,  9.9027e-01,  ...,  3.9114e+00,\n",
       "              1.3065e+00,  2.8157e+00],\n",
       "            [ 2.5929e-01,  5.4143e-01,  9.6880e-01,  ...,  9.6305e-01,\n",
       "              6.9592e-01,  4.8369e-01],\n",
       "            ...,\n",
       "            [ 9.2260e-01,  4.2927e+00,  1.1451e+00,  ...,  4.0437e+00,\n",
       "              1.0315e+00,  2.3265e+00],\n",
       "            [ 5.8345e-02,  2.2422e-01,  9.2055e-02,  ...,  3.0813e-01,\n",
       "              4.4163e-02,  2.1068e-01],\n",
       "            [ 5.1435e-01,  4.1602e-01,  5.1300e-01,  ...,  8.7475e-01,\n",
       "              6.0044e-01,  9.7272e-01]],\n",
       " \n",
       "           [[ 8.3206e-01,  3.0441e-02,  3.0016e+00,  ...,  1.1884e-01,\n",
       "              2.9950e+00,  7.2953e-01],\n",
       "            [ 1.5009e-01,  1.3900e+00,  5.5320e-01,  ...,  1.7614e+00,\n",
       "              3.4340e-01,  1.8044e+00],\n",
       "            [ 1.7942e+00,  5.1260e-01,  2.9927e+00,  ...,  1.0268e+00,\n",
       "              3.2564e+00,  5.1447e-01],\n",
       "            ...,\n",
       "            [ 5.4049e-02,  1.7991e+00,  6.1211e-01,  ...,  1.7078e+00,\n",
       "              3.5554e-01,  1.4377e+00],\n",
       "            [ 7.2272e-01,  1.9528e-01,  2.2835e-01,  ...,  2.5531e-01,\n",
       "              5.5436e-01,  1.2672e-01],\n",
       "            [ 7.6856e-02,  6.8382e-01, -1.3047e-01,  ...,  5.9162e-01,\n",
       "             -9.4050e-02,  7.8836e-01]]],\n",
       " \n",
       " \n",
       "          [[[-3.1891e-01, -2.7291e-01, -1.6763e-01,  ..., -1.7478e-01,\n",
       "             -2.2800e-01, -3.9467e-01],\n",
       "            [-4.3835e-02,  2.3410e-01,  1.7939e-02,  ...,  9.8053e-01,\n",
       "             -1.4294e-02,  8.6240e-01],\n",
       "            [-2.5703e-01, -2.1927e-01, -2.4805e-01,  ..., -1.7149e-02,\n",
       "             -2.8982e-01, -2.4451e-01],\n",
       "            ...,\n",
       "            [-1.4799e-01,  1.8828e-01,  1.1739e-01,  ...,  7.7886e-01,\n",
       "             -2.9122e-02,  1.1284e+00],\n",
       "            [-4.0459e-01, -3.0533e-01, -3.5859e-01,  ..., -1.7714e-01,\n",
       "             -3.4708e-01, -3.3489e-01],\n",
       "            [-2.3663e-01, -3.6305e-01, -1.6119e-01,  ..., -6.1590e-03,\n",
       "             -2.1068e-01, -2.7482e-01]],\n",
       " \n",
       "           [[ 4.2290e-01, -7.3591e-02,  1.0383e+00,  ...,  1.7315e-01,\n",
       "              1.1501e+00, -2.2757e-01],\n",
       "            [-3.2135e-01,  2.2409e-01,  1.5313e-02,  ...,  7.3855e-01,\n",
       "             -9.9827e-02,  5.2230e-01],\n",
       "            [ 1.3263e+00,  2.4971e-01,  1.7886e+00,  ...,  6.5283e-01,\n",
       "              1.4684e+00,  5.4275e-02],\n",
       "            ...,\n",
       "            [-3.5457e-01,  2.8322e-01,  1.7271e-01,  ...,  8.2082e-01,\n",
       "             -4.8675e-02,  5.7543e-01],\n",
       "            [ 6.9124e-01,  3.6047e-02,  9.8634e-01,  ...,  3.5894e-01,\n",
       "              6.8241e-01, -1.4587e-01],\n",
       "            [-3.0874e-01,  1.8839e-01, -1.5922e-01,  ...,  5.9832e-01,\n",
       "             -3.0020e-01,  2.5213e-02]],\n",
       " \n",
       "           [[-1.7081e-01,  2.0598e-01,  4.1232e-01,  ...,  2.7225e-01,\n",
       "              3.1886e-01, -1.3866e-01],\n",
       "            [ 2.0324e-01,  2.3707e+00,  7.9845e-01,  ...,  3.4184e+00,\n",
       "              8.2426e-01,  3.1024e+00],\n",
       "            [ 3.6618e-02,  2.7180e-01,  7.0479e-01,  ...,  4.4415e-01,\n",
       "              5.9520e-01,  1.5079e-01],\n",
       "            ...,\n",
       "            [ 1.8739e-01,  2.9477e+00,  1.0125e+00,  ...,  3.8141e+00,\n",
       "              9.8286e-01,  3.1474e+00],\n",
       "            [ 1.2953e-02,  1.1654e-01,  2.7860e-01,  ...,  2.9434e-01,\n",
       "              2.6306e-02,  1.4029e-01],\n",
       "            [ 2.6081e-03,  9.6028e-01,  5.0286e-01,  ...,  1.1166e+00,\n",
       "              4.0220e-01,  8.4000e-01]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[-1.7557e-01, -3.0076e-01,  3.3513e-01,  ...,  3.8694e-02,\n",
       "              5.7265e-01, -2.3835e-01],\n",
       "            [-4.9983e-01, -2.1656e-01, -2.3339e-01,  ...,  3.5496e-01,\n",
       "             -2.9756e-01,  3.1781e-01],\n",
       "            [ 1.6546e-01, -1.6785e-01,  8.2913e-01,  ...,  3.8341e-01,\n",
       "              9.2019e-01, -1.7348e-01],\n",
       "            ...,\n",
       "            [-4.6557e-01,  4.4354e-02, -1.6275e-01,  ...,  2.0428e-01,\n",
       "             -3.0929e-01,  2.1526e-01],\n",
       "            [-2.6228e-01, -4.2431e-01,  2.7441e-01,  ..., -8.5253e-02,\n",
       "              2.0912e-01, -3.0843e-01],\n",
       "            [-5.0905e-01, -3.0271e-01, -3.2457e-01,  ..., -4.0121e-03,\n",
       "             -3.6990e-01, -7.4546e-02]],\n",
       " \n",
       "           [[-4.6380e-01, -2.5869e-01, -2.4597e-01,  ..., -1.4404e-01,\n",
       "             -2.2307e-01, -2.6942e-01],\n",
       "            [-2.0550e-01,  6.4632e-01, -6.3915e-02,  ...,  1.0905e+00,\n",
       "              6.1055e-02,  6.5753e-01],\n",
       "            [-3.5281e-01, -2.4130e-01, -7.2402e-02,  ..., -7.4673e-02,\n",
       "             -1.8025e-01, -2.6412e-01],\n",
       "            ...,\n",
       "            [-9.0661e-02,  1.2412e+00, -2.7235e-03,  ...,  1.1428e+00,\n",
       "             -4.7611e-02,  4.6416e-01],\n",
       "            [-4.3222e-01, -3.6666e-01, -4.1890e-01,  ..., -3.3350e-01,\n",
       "             -4.3783e-01, -3.7201e-01],\n",
       "            [-2.5200e-01, -2.9087e-01, -2.5254e-01,  ..., -1.0957e-01,\n",
       "             -2.1798e-01, -7.0850e-02]],\n",
       " \n",
       "           [[-1.2644e-01, -4.4325e-01,  7.3100e-01,  ..., -4.0831e-01,\n",
       "              7.2837e-01, -1.6696e-01],\n",
       "            [-3.9596e-01,  9.4050e-02, -2.3665e-01,  ...,  2.4084e-01,\n",
       "             -3.1956e-01,  2.5783e-01],\n",
       "            [ 2.5379e-01, -2.5270e-01,  7.2746e-01,  ..., -4.9459e-02,\n",
       "              8.3169e-01, -2.5196e-01],\n",
       "            ...,\n",
       "            [-4.3392e-01,  2.5576e-01, -2.1337e-01,  ...,  2.1966e-01,\n",
       "             -3.1477e-01,  1.1291e-01],\n",
       "            [-1.6965e-01, -3.7810e-01, -3.6503e-01,  ..., -3.5438e-01,\n",
       "             -2.3619e-01, -4.0520e-01],\n",
       "            [-4.2491e-01, -1.8503e-01, -5.0684e-01,  ..., -2.2147e-01,\n",
       "             -4.9245e-01, -1.4371e-01]]]]], device='cuda:0',\n",
       "        grad_fn=<ConvolutionBackward0>),\n",
       " torch.Size([1, 3, 60, 120, 144]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, mean, logvar = model(tensor)\n",
    "output, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 60, 120, 144]), tensor([0, 1], device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax(dim= 1)\n",
    "output_soft = softmax(output)\n",
    "agmax_ouput = torch.argmax(output_soft, dim = 1)\n",
    "agmax_ouput.shape, torch.unique(agmax_ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]],\n",
       "\n",
       "         [[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]],\n",
       "\n",
       "         [[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [0, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 0, 1,  ..., 1, 1, 1],\n",
       "          [0, 1, 1,  ..., 1, 1, 1]],\n",
       "\n",
       "         [[0, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [0, 1, 0,  ..., 1, 0, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]],\n",
       "\n",
       "         [[1, 0, 1,  ..., 0, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 0],\n",
       "          [0, 1, 0,  ..., 1, 0, 1]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmax_ouput.to(device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "root_tmp = Path(\"/neurospin/dico/tsanchez/tmp/\")\n",
    "\n",
    "np.save(root_tmp / \"output_inference.npy\", agmax_ouput.cpu().numpy())\n",
    "np.save(root_tmp / \"input_inference.npy\", tensor.squeeze(0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  0.,  1.], dtype=float32),\n",
       " (20, 120, 144),\n",
       " array([0, 1]),\n",
       " (20, 120, 144))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_and_vermis = tensor[0][0][20:40][:][:].cpu().numpy()\n",
    "slice_output = agmax_ouput[0][20:40][:][:].cpu().numpy()\n",
    "np.unique(wm_and_vermis), wm_and_vermis.shape, np.unique(slice_output), slice_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_matter = np.where(wm_and_vermis == -1, 1, 0)\n",
    "sulci = np.where(wm_and_vermis == 1, 1, 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
